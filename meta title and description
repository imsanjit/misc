#Import the required packages
import pandas as pd
from bs4 import BeautifulSoup
from requests import get
from time import sleep
from random import randint
from time import time
h1=[]
title=[]
meta_description=[]
start_time = time()
requests = 0
#Import the csv file into a dataframe
df= pd.read_csv("E:/Python/urls.csv",header='infer')
#Iterate through the dataframe to get h1 tag and title tag of all urls
for index,row in df.iterrows():
    webpage= row['url']
    response = get(webpage)
    sleep(randint(8,15))
    requests += 1
    elapsed_time = time() - start_time
    html_soup = BeautifulSoup(response.text, 'html.parser')
    h1.append(html_soup.h1.text.strip())
    title.append(html_soup.title.text)
    

df['h1']=h1
df['title']=title
#Iterate through the dataframe to get meta description of the urls
for index,row in df.iterrows():
    webpage= row['url']
    response = get(webpage)
    html_soup = BeautifulSoup(response.text, 'html.parser')
    meta = html_soup.find_all('meta')
    for tag in meta:
        if 'name' in tag.attrs.keys() and tag.attrs['name'].strip().lower() in ['description']:
            meta_description.append(tag.attrs['content'])
            
df['meta_description']=meta_description

#Find the length of title tag and meta description tag
df['title_length']=df['title'].apply(len)
df['meta_description_length']=df['meta_description'].apply(len)
df.head()
