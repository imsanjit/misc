{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_in=input('Kindly Enter a url or list of urls sepatared by tab:  ').split(sep=' ')\n",
    "\n",
    "df = pd.DataFrame(columns =['URLs', 'H1', 'H2', 'H3', 'H4', 'H5', 'H6'])\n",
    "\n",
    "\n",
    "for x in url_in:\n",
    "    response=requests.get(x)\n",
    "    if response.status_code  == 200:\n",
    "        try:\n",
    "            html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            h =html_soup.find(\"body\")\n",
    "            \n",
    "            h1 = []\n",
    "            h2 = []\n",
    "            h3 = []\n",
    "            h4 = []\n",
    "            h5 = []\n",
    "            h6 = []\n",
    "            \n",
    "          \n",
    "            heading1 =h.find_all(\"h1\")\n",
    "            for text1 in heading1:\n",
    "                text1 = text1.get_text().strip()\n",
    "                h1.append(text1)\n",
    "\n",
    "            heading2 =h.find_all(\"h2\")\n",
    "            for text2 in heading2:\n",
    "                text2 = text2.get_text().strip()\n",
    "                h2.append(text2)\n",
    "                \n",
    "            heading3 =h.find_all(\"h3\")\n",
    "            for text3 in heading3:\n",
    "                text3 = text3.get_text().strip()\n",
    "                h3.append(text3)\n",
    "                \n",
    "            heading4 =h.find_all(\"h4\")\n",
    "            for text4 in heading4:\n",
    "                text4 = text4.get_text().strip()\n",
    "                h4.append(text4)\n",
    "                \n",
    "            heading5 =h.find_all(\"h5\")\n",
    "            for text5 in heading5:\n",
    "                text5 = text5.get_text().strip()\n",
    "                h5.append(text5)\n",
    "                \n",
    "            heading6 =h.find_all(\"h6\")\n",
    "            for text6 in heading6:\n",
    "                text6 = text6.get_text().strip()\n",
    "                h6.append(text6)\n",
    "                \n",
    "            df = df.append({'URLs':x, 'H1':h1, 'H2':h2, 'H3':h3, 'H4':h4, 'H5':h5, 'H6':h6}, ignore_index = True)\n",
    "\n",
    "            \n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "print(\"Process completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"headings.csv\", encoding='utf-8', index=False)\n",
    "print(\"CSV file created\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
